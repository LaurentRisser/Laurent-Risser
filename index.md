# Welcome to my portfolio

ABOUT ME:

Data Analyst/Scientist who takes pride in building models that translate data points into business insights. Built up my skills in diverse projects, now eager to apply the same knowledge to real-world business problems.

- Strong knowledge in Biology with M.Sc., Biology from Uppsala University.
- 2+ years of experience in statistical research.
- Strong understanding of statistics, machine learning, web scraping and regression and classification. Example packages: numpy, pandas, scikit-learn, LGBM.
- Practical experience in predictive modelling (logistic regression, decision- tree), NLP and A/B testing.
- Proficient in statistical programming tools such as Python, R and SQL.
- Strong knowledge of Big Data tools (Spark, Hadoop), AWS cloud computing (EC2, EMR, S3, Redshift) and databases (Oracle, Redshift, MySQL).
- Experience with visualization tools (Tableau, Matplotlib, Plotly, ggplot2).
- Excellent analytical and problem-solving skills.
- Bilingual English and French.
- Author for Towards Data Science, Data Driven Investor and Analytics Vidhya on Medium

Certification:
AWS Cloud Practitioner

You can connect with my on LinkedIn [here](https://www.linkedin.com/in/risserl/)

My [Resume](https://drive.google.com/file/d/1atQGP0nNCwwhLvURgtV_-ax-SNvYy4_O/view?usp=sharing) 

# My projects

This portfolio is a compilation of projects which I created for data analysis or for exploration of machine learning algorithms. 

## Get to know your friends with Natural Language Processing (NLP)
### Project Type: Data Cleaning, Visualisation and Data Analysis
### [Medium Article - Get to know your friends with Natural Language Processing (NLP)](https://towardsdatascience.com/get-to-know-your-friends-with-natural-language-processing-nlp-38a1f6e56e09) 

### [Githup repo](https://github.com/walkyrie67/whatsapp_analysis)

In this project worked on a group chat on WhatsApp. I collected, cleaned and analyzed the data through a few plots done with Plotly. 

![wordcloud](images/word_cloud.png "Word cloud")

## Housing Market, Web scrapping & Analysis
### Project Type: Data Collection, Analysis, Visualisation and Machine Learning
### [Medium Article - How to Scrap the Housing Market](https://medium.com/datadriveninvestor/how-to-scrap-the-housing-market-9081a1610fea?source=friends_link&sk=922dee31b18d73dbc03b1ff17dbffba0) 
### [Medium Article - House Pricing in Toronto, Exploratory Data Analysis and Correlations](https://medium.com/datadriveninvestor/house-pricing-in-toronto-exploratory-data-analysis-and-correlations-45d2f11475f4?source=friends_link&sk=86f7cc2f3b0dc90b3b4aa5f152c82d6e) 

### [Githup repo](https://github.com/walkyrie67/toronto_housing_webscraping/tree/master)

In this project I extracted the data using beautil soup through web scrapping and also cleaned and manipulated the data using Pandas. Then, I analyze the data and identify some trends in the market and give a few recommendations for potential renters.

![PricevsSquare](images/pricevssquare.png "PricevsSquare")

## Social Analysis with Twitter Data
### Project Type: Data Engineering and AWS
### [Medium Article - How to Create a Dataset with Twitter and Cloud Computing](https://towardsdatascience.com/how-to-create-a-dataset-with-twitter-and-cloud-computing-fcd82837d313?source=friends_link&sk=b56db9035ff3e59a68fbc19fbf211539)

### [Githup repo](https://github.com/walkyrie67/project2_big_data_gilets_jaunes)

In this project I setup an ETL flow from the Twitter API to an S3 bucket. I use different services from AWS and I manipulated data by using Python and Shell languages.

![ETL](images/ETL.png "ETL")

## Predicting flight delays in the U.S.
### Project Type: Data Analysis and Machine Learning
### [Medium Article - Will your flight be late?](https://medium.com/analytics-vidhya/will-your-flight-be-late-36818ffe52b3?source=friends_link&sk=b12b06c3463c125b1370650e8b52bc9f) 

### [Githup repo](https://github.com/walkyrie67/flight_delay_prediction/blob/master/-Copy1.ipynb)

In this project, I develop a model aimed at predicting flight delays at take-off. Among then, I comment on the importance of the separation of the dataset during the traning stage and how cross-validation helps in determing accurate model parameters. I show how to build linear and polynomial models for univariate or multivariate regressions and also, I give some insight on the reason why regularisation helps us in developing models that generalize well.

![Delays throughout one day](images/departure_time.png "Delays throughout one day")


